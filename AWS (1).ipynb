{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOx2YEU_njhX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Difference between AWS Regions, Availability Zones, and Edge Locations\n",
        "Regions: Geographically isolated areas (e.g., us-east-1, ap-south-1). Each region contains multiple availability zones.\n",
        "\n",
        "\n",
        "Availability Zones (AZs): Data centers within a region. They provide high availability and fault tolerance.\n",
        "\n",
        "\n",
        "Edge Locations: Used by CloudFront for content delivery with low latency to end-users.\n",
        "\n",
        "\n",
        "Importance for Data Analysis & Latency-Sensitive Applications:\n",
        "\n",
        "\n",
        "Choose regions close to your users for low latency.\n",
        "\n",
        "\n",
        "Use AZs for high availability.\n",
        "\n",
        "\n",
        "Use edge locations for fast content delivery.\n",
        "\n",
        "\n",
        "\n",
        "2. List all AWS regions using AWS CLI\n",
        "aws ec2 describe-regions --all-regions --query \"Regions[*].RegionName\"\n",
        "\n",
        "Sample Output:\n",
        "[\n",
        "  \"af-south-1\",\n",
        "  \"ap-east-1\",\n",
        "  \"ap-south-1\",\n",
        "  \"ap-northeast-1\",\n",
        "  \"eu-west-1\",\n",
        "  ...\n",
        "]\n",
        "\n",
        "\n",
        "3. Create IAM User with Least Privilege for S3\n",
        "Policy JSON:\n",
        "{\n",
        "  \"Version\": \"2012-10-17\",\n",
        "  \"Statement\": [\n",
        "    {\n",
        "      \"Effect\": \"Allow\",\n",
        "      \"Action\": [\n",
        "        \"s3:ListBucket\",\n",
        "        \"s3:GetObject\",\n",
        "        \"s3:PutObject\"\n",
        "      ],\n",
        "      \"Resource\": [\n",
        "        \"arn:aws:s3:::your-bucket-name\",\n",
        "        \"arn:aws:s3:::your-bucket-name/*\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "\n",
        "4. Compare S3 Storage Classes\n",
        "Storage Class\n",
        "Use Case\n",
        "S3 Standard\n",
        "Frequently accessed data.\n",
        "S3 Intelligent-Tiering\n",
        "Automatically moves data between tiers.\n",
        "S3 Glacier\n",
        "Archival. Use when data is rarely accessed.\n",
        "\n",
        "\n",
        "5. Create S3 Bucket, Upload File, Enable Versioning\n",
        "aws s3api create-bucket --bucket my-dataset-bucket --region ap-south-1\n",
        "aws s3api put-bucket-versioning --bucket my-dataset-bucket --versioning-configuration Status=Enabled\n",
        "aws s3 cp data.csv s3://my-dataset-bucket/data.csv\n",
        "aws s3 cp updated_data.csv s3://my-dataset-bucket/data.csv\n",
        "aws s3api list-object-versions --bucket my-dataset-bucket\n",
        "\n",
        "\n",
        "6. Lifecycle Policy: Move to Glacier after 30 days, Delete after 90\n",
        "{\n",
        "  \"Rules\": [\n",
        "    {\n",
        "      \"ID\": \"MoveToGlacierThenDelete\",\n",
        "      \"Status\": \"Enabled\",\n",
        "      \"Prefix\": \"\",\n",
        "      \"Transitions\": [\n",
        "        {\n",
        "          \"Days\": 30,\n",
        "          \"StorageClass\": \"GLACIER\"\n",
        "        }\n",
        "      ],\n",
        "      \"Expiration\": {\n",
        "        \"Days\": 90\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "\n",
        "7. RDS vs DynamoDB vs Redshift\n",
        "Service\n",
        "Use Case\n",
        "RDS\n",
        "Transactional data (e.g., orders, billing)\n",
        "DynamoDB\n",
        "Serverless NoSQL (e.g., user sessions)\n",
        "Redshift\n",
        "OLAP, large-scale analytics queries\n",
        "\n",
        "\n",
        "8. DynamoDB + Lambda for S3 Trigger\n",
        "Create Table: aws dynamodb create-table ...\n",
        "\n",
        "\n",
        "Insert Records:\n",
        "\n",
        "\n",
        "aws dynamodb put-item --table-name myTable --item '{\"ID\":{\"S\":\"1\"}, \"Name\":{\"S\":\"Alice\"}}'\n",
        "\n",
        "Lambda Function (Python):\n",
        "\n",
        "\n",
        "import boto3\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    s3 = event['Records'][0]['s3']\n",
        "    filename = s3['object']['key']\n",
        "    dynamodb = boto3.client('dynamodb')\n",
        "    dynamodb.put_item(\n",
        "        TableName='myTable',\n",
        "        Item={\n",
        "            'ID': {'S': filename},\n",
        "            'Status': {'S': 'Uploaded'}\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "9. Serverless Computing and AWS Lambda\n",
        "Definition: Serverless allows you to run code without managing servers.\n",
        "\n",
        "\n",
        "Pros: Auto-scaling, cost-efficient, easy to deploy.\n",
        "\n",
        "\n",
        "Cons: Cold starts, timeout limits, debugging difficulty.\n",
        "\n",
        "\n",
        "For Pipelines: Lambda is ideal for lightweight, event-driven processing.\n",
        "\n",
        "\n",
        "\n",
        "10. Lambda Logging to CloudWatch on S3 Upload\n",
        "import logging\n",
        "import time\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    file = event['Records'][0]['s3']['object']\n",
        "    logger.info(f\"File: {file['key']}, Size: {file['size']}, Time: {time.time()}\")\n",
        "\n",
        "\n",
        "11. AWS Glue: Crawl, Catalog, Convert CSV to Parquet\n",
        "Steps:\n",
        "\n",
        "\n",
        "Create Crawler â†’ S3 Path\n",
        "\n",
        "\n",
        "Create Glue Job:\n",
        "\n",
        "\n",
        "import sys\n",
        "from awsglue.transforms import *\n",
        "from awsglue.utils import getResolvedOptions\n",
        "from pyspark.context import SparkContext\n",
        "from awsglue.context import GlueContext\n",
        "\n",
        "glueContext = GlueContext(SparkContext.getOrCreate())\n",
        "datasource = glueContext.create_dynamic_frame.from_catalog(database=\"mydb\", table_name=\"mytable\")\n",
        "glueContext.write_dynamic_frame.from_options(frame=datasource, connection_type=\"s3\", format=\"parquet\", connection_options={\"path\": \"s3://output-path/\"})\n",
        "\n",
        "\n",
        "12. Kinesis Data Family Comparison\n",
        "Service\n",
        "Use Case Example\n",
        "Kinesis Data Streams\n",
        "Real-time clickstream ingestion.\n",
        "Kinesis Firehose\n",
        "Stream logs to S3/Redshift/Elasticsearch.\n",
        "Kinesis Analytics\n",
        "SQL queries on streaming data.\n",
        "\n",
        "\n",
        "13. Columnar Storage in Redshift\n",
        "Stores data by columns, not rows.\n",
        "\n",
        "\n",
        "Benefits: Faster queries, better compression, ideal for analytics.\n",
        "\n",
        "\n",
        "\n",
        "14. Load CSV into Redshift\n",
        "Table Schema:\n",
        "CREATE TABLE sales(id INT, product VARCHAR, amount DECIMAL);\n",
        "\n",
        "COPY Command:\n",
        "COPY sales FROM 's3://mybucket/sales.csv'\n",
        "CREDENTIALS 'aws_iam_role=arn:aws:iam::xxxx:role/myRedshiftRole'\n",
        "CSV IGNOREHEADER 1;\n",
        "\n",
        "Query Output:\n",
        "SELECT * FROM sales LIMIT 5;\n",
        "\n",
        "\n",
        "15. Glue Data Catalog in Athena\n",
        "Role: Central metadata repository.\n",
        "\n",
        "\n",
        "Schema-on-Read: Athena reads the data schema during query time. No data movement or transformation needed beforehand.\n",
        "\n",
        "\n",
        "\n",
        "16. Create Athena Table from S3 + Query\n",
        "CREATE EXTERNAL TABLE sales (\n",
        "  id INT,\n",
        "  product STRING,\n",
        "  amount DOUBLE\n",
        ")\n",
        "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\n",
        "WITH SERDEPROPERTIES (\"separatorChar\" = \",\")\n",
        "LOCATION 's3://mybucket/sales/';\n",
        "\n",
        "SELECT * FROM sales WHERE amount > 100;\n",
        "\n",
        "\n",
        "17. Amazon QuickSight for BI\n",
        "Serverless BI tool.\n",
        "\n",
        "\n",
        "SPICE: In-memory storage for faster queries.\n",
        "\n",
        "\n",
        "Embedded Dashboards: Integrate into custom web apps.\n",
        "\n",
        "\n",
        "\n",
        "18. QuickSight Dashboard from Athena/Redshift\n",
        "Connect to Athena or Redshift.\n",
        "\n",
        "\n",
        "Create calculated field (e.g., Profit = Revenue - Cost).\n",
        "\n",
        "\n",
        "Add filters (e.g., Region = 'North').\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "19. CloudWatch vs CloudTrail\n",
        "Feature\n",
        "CloudWatch\n",
        "CloudTrail\n",
        "Purpose\n",
        "Logs, metrics, monitoring\n",
        "API activity auditing\n",
        "Pipeline Role\n",
        "Monitor Glue, Lambda, etc.\n",
        "Track user/API interactions\n",
        "\n",
        "\n",
        "20. End-to-End AWS Data Pipeline\n",
        "Pipeline:\n",
        "Ingestion: S3 (Raw data uploaded via APIs or directly).\n",
        "\n",
        "\n",
        "Trigger: Lambda (Triggers Glue job on file upload).\n",
        "\n",
        "\n",
        "Transformation: AWS Glue (ETL from CSV to Parquet).\n",
        "\n",
        "\n",
        "Querying: Athena (Run SQL queries over S3).\n",
        "\n",
        "\n",
        "Visualization: QuickSight (Dashboards built on Athena tables).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gXC5P8sXnlG9"
      }
    }
  ]
}