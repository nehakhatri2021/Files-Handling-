# -*- coding: utf-8 -*-
"""DecisionTree1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l64nZ0VTJ7hXdocUWObmefeqCOcJISMr
"""



"""
**What is a Decision Tree, and how does it work?**
A Decision Tree is a supervised learning algorithm used for classification and regression that splits data into subsets based on feature values, creating a tree-like model of decisions to predict outcomes.

---

**What are impurity measures in Decision Trees?**
Impurity measures quantify how mixed the classes are in a node. Common ones include Gini Impurity and Entropy.

---

**What is the mathematical formula for Gini Impurity?**

$$
Gini = 1 - \sum_{i=1}^C p_i^2
$$

where $p_i$ is the probability of class $i$ in the node.

---

**What is the mathematical formula for Entropy?**

$$
Entropy = -\sum_{i=1}^C p_i \log_2(p_i)
$$

---

**What is Information Gain, and how is it used in Decision Trees?**
Information Gain measures the reduction in impurity (Entropy or Gini) after a split. It helps select the best feature to split on.

---

**What is the difference between Gini Impurity and Entropy?**
Both measure impurity; Gini tends to be faster and less computationally intensive, while Entropy is based on information theory and can be more sensitive to changes in class probabilities.

---

**What is the mathematical explanation behind Decision Trees?**
Decision Trees recursively partition the feature space by choosing splits that maximize Information Gain (or reduce impurity), until stopping criteria are met.

---

**What is Pre-Pruning in Decision Trees?**
Stopping tree growth early based on criteria like max depth or minimum samples per leaf to prevent overfitting.

---

**What is Post-Pruning in Decision Trees?**
Growing a full tree first and then pruning back nodes that don't improve model generalization.

---

**What is the difference between Pre-Pruning and Post-Pruning?**
Pre-pruning stops tree growth early; post-pruning removes branches after full growth.

---

**What is a Decision Tree Regressor?**
A decision tree model used for regression tasks, predicting continuous outcomes by averaging target values in leaves.

---

**What are the advantages and disadvantages of Decision Trees?**
Advantages: Easy to interpret, handles nonlinear data, requires little data preprocessing.
Disadvantages: Prone to overfitting, can be unstable with small data changes.

---

**How does a Decision Tree handle missing values?**
Some implementations handle missing values by surrogate splits or by assigning the most common value; others require preprocessing.

---

**How does a Decision Tree handle categorical features?**
It splits nodes based on categories by grouping or binary splitting on category membership.

---

**What are some real-world applications of Decision Trees?**
Credit scoring, medical diagnosis, customer segmentation, fraud detection.

"""